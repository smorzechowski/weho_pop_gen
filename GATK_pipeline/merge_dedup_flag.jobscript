#!/bin/bash
#SBATCH -N 1
#SBATCH -n 12
#SBATCH -p edwards,shared
#SBATCH -e log/merge_dedup_flag%A.err
#SBATCH -o log/merge_dedup_flag%A.out
#SBATCH -J merge_dedup_flag
#SBATCH --mem=60g
#SBATCH --time=24:00:00
#SBATCH --account=wakeley_lab

# Input parameters
RAW_DIR='/n/holyscratch01/edwards_lab/smorzechowski/meliphagid/analysis/2024-08-12/12-bwa/raw'
MERGE_DIR='/n/holyscratch01/edwards_lab/smorzechowski/meliphagid/analysis/2024-08-12/12-bwa/merge'
DEDUP_DIR='/n/holyscratch01/edwards_lab/smorzechowski/meliphagid/analysis/2024-08-12/12-bwa/dedup_flag'
TMP_DIR='/n/holyscratch01/edwards_lab/smorzechowski/meliphagid/analysis/2024-08-12/12-bwa/tmp'
GENOME='/n/holylfs04/LABS/edwards_lab/Lab/smorzechowski/meliphagid/ReferenceAssemblies/Nleucotis_hifi_v1.0_hc_sm_fx_scaffolded_PAR_masked.fasta'
INDEXBASE='Nleucotis_hifi_v1.0_hc_sm_fx_scaffolded_PAR_masked'
CPU=12
FLOWCELL='LH00541'
FLOWCELL_BARCODE='22KV7YLT3'
SAMPLE=$1
PLATFORM='Illumina'
LIBPREP='P536'

module purge
module load python
source activate samtools

module load jdk/20.0.1-fasrc01

PICARD='/n/home09/smorzechowski/bin/picard/build/libs/picard.jar'
# this comes from ArimaGenomics mapping_pipeline
STATS='/n/home09/smorzechowski/bin/get_stats.pl'
BWA_PATH='/n/home09/smorzechowski/bin/bwa'

#Check output directories exist & create them as needed
[ -d $RAW_DIR ] || mkdir -p $RAW_DIR
[ -d $TMP_DIR ] || mkdir -p $TMP_DIR
[ -d $DEDUP_DIR ] || mkdir -p $DEDUP_DIR
[ -d $MERGE_DIR ] || mkdir -p $MERGE_DIR

# merge the two bam files for each sample
#samtools merge -r $MERGE_DIR/${SAMPLE}_bwa_merge.bam $RAW_DIR/${SAMPLE}_L003_bwa_sort.bam $RAW_DIR/${SAMPLE}_L004_bwa_sort.bam

# view the header to look at read groups
#samtools view -H $MERGE_DIR/${SAMPLE}_bwa_merge.bam

# sort the merged file again
#samtools sort $MERGE_DIR/${SAMPLE}_bwa_merge.bam -@ $CPU --output-fmt BAM -o $MERGE_DIR/${SAMPLE}_bwa_merge_sort.bam

# index the sorted merged bam files
# not sure if this is necessary?
#samtools index $RAW_DIR/${SAMPLE}_bwa_merge_sort.bam

# get summary of the alignment
#samtools flagstat $MERGE_DIR/${SAMPLE}_bwa_merge_sort.bam > $MERGE_DIR/${SAMPLE}_bwa_merge_sort.bam.flagstat

# Mark duplicates with Picard - just flag, do not remove
#-XX:-UseGCOverheadLimit -Djava.io.tmpdir=temp/ \
java -Xmx30G \
-jar $PICARD MarkDuplicates \
TMP_DIR=$TMP_DIR \
INPUT=$MERGE_DIR/${SAMPLE}_bwa_merge_sort.bam \
OUTPUT=$DEDUP_DIR/${SAMPLE}_bwa_merge_dedup_flag.bam \
METRICS_FILE=$DEDUP_DIR/${SAMPLE}_bwa_merge_dedup_flag_metrics.txt \
REMOVE_DUPLICATES=false \
TAGGING_POLICY=All \
ASSUME_SORTED=true \

# remove the unsorted merged file, no need to keep anymore
# rm $MERGE_DIR/${SAMPLE}_bwa_merge.bam

# Sort the reads normally again
samtools sort -@ $CPU $DEDUP_DIR/${SAMPLE}_bwa_merge_dedup_flag.bam -o $DEDUP_DIR/${SAMPLE}_bwa_merge_dedup_flag_sort.bam

# remove the dedup unsorted file, no need to keep anymore
#rm $DEDUP_DIR/${SAMPLE}_bwa_merge_dedup.bam

# validate the bam files again
java -Xmx30G \
-jar $PICARD ValidateSamFile \
      I=$DEDUP_DIR/${SAMPLE}_bwa_merge_dedup_flag_sort.bam \
      MODE=SUMMARY

# fix mate information
# output will be sorted automatically the same as input, e.g. by coordinate
java -Xmx30G \
-jar $PICARD FixMateInformation \
       I=$DEDUP_DIR/${SAMPLE}_bwa_merge_dedup_flag_sort.bam \
       O=$DEDUP_DIR/${SAMPLE}_bwa_merge_dedup_flag_sort_fixmate.bam \
       ADD_MATE_CIGAR=true

# Index the final bam files again
samtools index $DEDUP_DIR/${SAMPLE}_bwa_merge_dedup_flag_sort_fixmate.bam

# output stats on mapping using ArimaGenomics perl script
perl $STATS $DEDUP_DIR/${SAMPLE}_bwa_merge_dedup_flag_sort_fixmate.bam > $DEDUP_DIR/${SAMPLE}_bwa_merge_dedup_flag_sort_fixmate.bam.stats


# validate the fixed mate bam files
java -Xmx30G \
-jar $PICARD ValidateSamFile \
      I=$DEDUP_DIR/${SAMPLE}_bwa_merge_dedup_flag_sort_fixmate.bam \
      MODE=SUMMARY
